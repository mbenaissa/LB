// Copyright (c) 2010-2014 Etsy, see LICENSE.etsy
// Copyright (C) 2014 Strongloop, see LICENSE.md
var assert = require('assert');
var async = require('async');
var debug = require('debug')('strong-statsd:server');
var helpers = require('./helpers')
var events = require('events')
var set = require('./set')
var pm = require('./process_metrics')
var util = require('util');

function once(f) {
  var called;
  return function() {
    if (called) return;
    called = true;
    f.apply(null, arguments);
  }
}

module.exports = Server;

function Server() {
  // initialize data structures with defaults for statsd stats
  var keyCounter = {};
  var counters = {};
  var timers = {};
  var timer_counters = {};
  var gauges = {};
  var sets = {};
  var counter_rates = {};
  var timer_data = {};
  var pctThreshold = null;
  var flushInterval;
  var flushIntervalTimer;
  var startup_time = Math.round(new Date().getTime() / 1000);
  var backendEvents = new events.EventEmitter();
  var old_timestamp = 0;
  var timestamp_lag_namespace;
  var backends = {}; // There can be multiple backends, keyed by name
  var server; // There can be only one server

  // Load and init the backend from the backends/ directory.
  function loadBackend(config, name) {
    debug("loading backend: %s", name);

    var backendmod = require(name);

    // XXX(SR) this API can only fail synchronously, which is pretty limiting
    var ret = backendmod.init(startup_time, config, backendEvents, l);

    if (!ret)
      throw Error("Failed to load backend: " + name);

    backends[name] = backendmod;
  }

  // Load and init the server from the servers/ directory.
  // The callback mimics the dgram 'message' event parameters (msg, rinfo)
  //   msg: the message received by the server. may contain more than one metric
  //   rinfo: contains remote address information and message length
  //      (attributes are .address, .port, .family, .size - you're welcome)
  function startServer(config, name, callback) {
    debug("starting server: %s", name);

    var servermod = require(name);
    var server = servermod.start(config, callback);
    if (!server)
      throw Error("Failed to load server: " + name);

    return server;
  }

  // global for conf
  var conf;

  // Flush metrics to each backend.
  function flushMetrics() {
    var time_stamp = Math.round(new Date().getTime() / 1000);
    if (old_timestamp > 0) {
      gauges[timestamp_lag_namespace] = (time_stamp - old_timestamp - (Number(conf.flushInterval)/1000));
    }
    old_timestamp = time_stamp;

    var metrics_hash = {
      counters: counters,
      gauges: gauges,
      timers: timers,
      timer_counters: timer_counters,
      sets: sets,
      counter_rates: counter_rates,
      timer_data: timer_data,
      pctThreshold: pctThreshold,
      histogram: conf.histogram
    };

    debug('flush at %s: %j', time_stamp, metrics_hash);

    // After all listeners, reset the stats
    backendEvents.once('flush', function clear_metrics(ts, metrics) {
      // TODO: a lot of this should be moved up into an init/constructor so we don't have to do it every
      // single flushInterval....
      // allows us to flag all of these on with a single config but still override them individually
      conf.deleteIdleStats = conf.deleteIdleStats !== undefined ? conf.deleteIdleStats : false;
      if (conf.deleteIdleStats) {
        conf.deleteCounters = conf.deleteCounters !== undefined ? conf.deleteCounters : true;
        conf.deleteTimers = conf.deleteTimers !== undefined ? conf.deleteTimers : true;
        conf.deleteSets = conf.deleteSets !== undefined ? conf.deleteSets : true;
        conf.deleteGauges = conf.deleteGauges !== undefined ? conf.deleteGauges : true;
      }

      // Clear the counters
      conf.deleteCounters = conf.deleteCounters || false;
      for (var counter_key in metrics.counters) {
        if (conf.deleteCounters) {
          if ((counter_key.indexOf("packets_received") != -1) || (counter_key.indexOf("bad_lines_seen") != -1)) {
            metrics.counters[counter_key] = 0;
          } else {
            delete(metrics.counters[counter_key]);
          }
        } else {
          metrics.counters[counter_key] = 0;
        }
      }

      // Clear the timers
      conf.deleteTimers = conf.deleteTimers || false;
      for (var timer_key in metrics.timers) {
        if (conf.deleteTimers) {
          delete(metrics.timers[timer_key]);
          delete(metrics.timer_counters[timer_key]);
        } else {
          metrics.timers[timer_key] = [];
          metrics.timer_counters[timer_key] = 0;
        }
      }

      // Clear the sets
      conf.deleteSets = conf.deleteSets || false;
      for (var set_key in metrics.sets) {
        if (conf.deleteSets) {
          delete(metrics.sets[set_key]);
        } else {
          metrics.sets[set_key] = new set.Set();
        }
      }

      // normally gauges are not reset.  so if we don't delete them, continue to persist previous value
      conf.deleteGauges = conf.deleteGauges || false;
      if (conf.deleteGauges) {
        for (var gauge_key in metrics.gauges) {
          delete(metrics.gauges[gauge_key]);
        }
      }
    });

    pm.process_metrics(metrics_hash, flushInterval, time_stamp, function emitFlush(metrics) {
      backendEvents.emit('flush', time_stamp, metrics);
    });

  }

  var stats = {
    messages: {
      last_msg_seen: startup_time,
      bad_lines_seen: 0
    }
  };

  var l = {};

  this.stop = function(callback) {
    clearInterval(flushIntervalTimer);
    server.once('close', function() {
      // close callbacks synchronously!
      process.nextTick(callback);
    });
    server.close();
  };

  this.start = function start(config, log, callback) {
    assert(config, 'config required');
    assert(log, 'log required');
    assert(callback, 'callback required');

    conf = config;
    l.log = log;
    callback = once(callback);

    // setup config for stats prefix
    var prefixStats = config.prefixStats;
    prefixStats = prefixStats !== undefined ? prefixStats : "statsd";
    //setup the names for the stats stored in counters{}
    bad_lines_seen   = prefixStats + ".bad_lines_seen";
    packets_received = prefixStats + ".packets_received";
    timestamp_lag_namespace = prefixStats + ".timestamp_lag";

    //now set to zero so we can increment them
    counters[bad_lines_seen]   = 0;
    counters[packets_received] = 0;

    // key counting
    var keyFlushInterval = Number((config.keyFlush && config.keyFlush.interval) || 0);

    // Setup backends, which might throw
    try {
      if (config.backends) {
        for (var i = 0; i < config.backends.length; i++) {
          loadBackend(config, config.backends[i]);
        }
      }
    } catch(er) {
      return callback(er);
    }

    async.each(config.backends || [], check, function(er) {
      debug('backends checked: %s', er);
      if (er) return callback(er);

      startListening();
    });

    function check(name, callback) {
      backend = backends[name];
      if (!backend.check) return callback();
      backend.check(callback);
    }

    function startListening() {
      var serverName = config.server || './servers/ipc'
      server = startServer(config, serverName, ondata);

      server.once('error', function(er) {
        // Don't callback for run-time errors, just the initial listen error
        return callback(er);
      });

      server.once('listening', function() {
        // Make sure we don't unref until we've started, or our caller might
        // prematurely exit before we callback.
        this.unref();

        pctThreshold = config.percentThreshold || 90;
        if (!Array.isArray(pctThreshold)) {
          pctThreshold = [ pctThreshold ]; // listify percentiles so single values work the same
        }

        flushInterval = Number(config.flushInterval || 10000);
        config.flushInterval = flushInterval;

        // Setup the flush timer
        flushIntervalTimer = setInterval(flushMetrics, flushInterval);

        flushIntervalTimer.unref();

        return callback(null, this);
      });
    }

    function ondata(msg, rinfo) {
      backendEvents.emit('packet', msg, rinfo);
      counters[packets_received]++;
      var packet_data = msg.toString();
      if (packet_data.indexOf("\n") > -1) {
        var metrics = packet_data.split("\n");
      } else {
        var metrics = [ packet_data ] ;
      }

      for (var midx in metrics) {
        if (metrics[midx].length === 0) {
          continue;
        }
        if (config.dumpMessages) {
          l.log(metrics[midx].toString());
        }
        var bits = metrics[midx].toString().split(':');
        var key = bits.shift()
        .replace(/\s+/g, '_')
        .replace(/\//g, '-')
          .replace(/[^a-zA-Z_\-0-9\.]/g, '');

          if (keyFlushInterval > 0) {
            if (! keyCounter[key]) {
              keyCounter[key] = 0;
            }
            keyCounter[key] += 1;
          }

          if (bits.length === 0) {
            bits.push("1");
          }

          for (var i = 0; i < bits.length; i++) {
            var sampleRate = 1;
            var fields = bits[i].split("|");
            if (!helpers.is_valid_packet(fields)) {
              l.log('Bad line: ' + fields + ' in msg "' + metrics[midx] +'"');
              counters[bad_lines_seen]++;
              stats.messages.bad_lines_seen++;
              continue;
            }
            if (fields[2]) {
              sampleRate = Number(fields[2].match(/^@([\d\.]+)/)[1]);
            }

            var metric_type = fields[1].trim();
            if (metric_type === "ms") {
              if (! timers[key]) {
                timers[key] = [];
                timer_counters[key] = 0;
              }
              timers[key].push(Number(fields[0] || 0));
              timer_counters[key] += (1 / sampleRate);
            } else if (metric_type === "g") {
              if (gauges[key] && fields[0].match(/^[-+]/)) {
                gauges[key] += Number(fields[0] || 0);
              } else {
                gauges[key] = Number(fields[0] || 0);
              }
            } else if (metric_type === "s") {
              if (! sets[key]) {
                sets[key] = new set.Set();
              }
              sets[key].insert(fields[0] || '0');
            } else {
              if (! counters[key]) {
                counters[key] = 0;
              }
              counters[key] += Number(fields[0] || 1) * (1 / sampleRate);
            }
          }
      }

      stats.messages.last_msg_seen = Math.round(new Date().getTime() / 1000);
    }
  }
};
